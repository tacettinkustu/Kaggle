{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in c:\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.18.5)\n",
      "Requirement already satisfied: Shapely in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.7.1)\n",
      "Requirement already satisfied: imageio in c:\\anaconda3\\lib\\site-packages (from imgaug) (2.9.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\anaconda3\\lib\\site-packages (from imgaug) (0.16.2)\n",
      "Requirement already satisfied: Pillow in c:\\anaconda3\\lib\\site-packages (from imgaug) (7.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\anaconda3\\lib\\site-packages (from imgaug) (4.2.0.34)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda3\\lib\\site-packages (from imgaug) (3.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.2)\n",
      "Requirement already satisfied: mlxtend in c:\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from mlxtend) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->mlxtend) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imgaug\n",
    "!pip install mlxtend\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Path('C:/Users/tcttn/Desktop/tank/data/train/') \n",
    "validation_data = Path('C:/Users/tcttn/Desktop/tank/data/test/')\n",
    "labels_path = Path('C:/Users/tcttn/Desktop/tank/data/weapons.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'abrams', 1: 'leopard', 2: 't90'}\n"
     ]
    }
   ],
   "source": [
    "labels_dict= {'abrams':0, 'leopard':1, 't90':2}\n",
    "\n",
    "# map labels to common names\n",
    "names_dict = dict(zip(labels_dict.values(), labels_dict.keys()))\n",
    "print(names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traininng samples:  240\n",
      "Number of validation samples:  47\n",
      "\n",
      "                                                image  label\n",
      "0  C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90...      2\n",
      "1  C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90...      2\n",
      "2  C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\...      0\n",
      "3  C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\...      0\n",
      "4  C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\...      0 \n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "                                                image  label\n",
      "0  C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\a...      0\n",
      "1  C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\a...      0\n",
      "2  C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_...      2\n",
      "3  C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_...      2\n",
      "4  C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\...      1\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "for folder in os.listdir(training_data):\n",
    "    # Define the path to the images\n",
    "    imgs_path = training_data / folder\n",
    "    \n",
    "    # Get the list of all the images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    \n",
    "    # Store each image path and corresponding label \n",
    "    for img_name in imgs:\n",
    "        train_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Creating dataframe for validation data in a similar fashion\n",
    "valid_df = []\n",
    "for folder in os.listdir(validation_data):\n",
    "    imgs_path = validation_data / folder\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    for img_name in imgs:\n",
    "        valid_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "        \n",
    "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# How many samples do we have in our training and validation data?\n",
    "print(\"Number of traininng samples: \", len(train_df))\n",
    "print(\"Number of validation samples: \", len(valid_df))\n",
    "\n",
    "# sneak peek of the training and validation dataframes\n",
    "print(\"\\n\",train_df.head(), \"\\n\")\n",
    "print(\"=================================================================\\n\")\n",
    "print(\"\\n\", valid_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants(not truly though!) \n",
    "\n",
    "# dimensions to consider for the images\n",
    "img_rows, img_cols, img_channels = 224,224,3\n",
    "\n",
    "# batch size for training  \n",
    "batch_size=8\n",
    "\n",
    "# total number of classes in the dataset\n",
    "nb_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence \n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, batch_size, is_validation_data=False):\n",
    "    #print(\"hello\")\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    nb_batches = int(np.ceil(n/batch_size))\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        if not is_validation_data:\n",
    "            # shuffle indices for the training data\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        for i in range(nb_batches):\n",
    "            # get the next batch \n",
    "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            # process the next batch\n",
    "            for j, idx in enumerate(next_batch_indices):\n",
    "                print(data.iloc[idx][\"image\"])\n",
    "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
    "                #print(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                #print(data.iloc[idx][\"label\"])\n",
    "                label = data.iloc[idx][\"label\"]\n",
    "                \n",
    "                if not is_validation_data:\n",
    "                    img = seq.augment_image(img)\n",
    "                #print(img.size)\n",
    "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
    "            #print(preprocess_input(batch_data))\n",
    "            batch_data = preprocess_input(batch_data)\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = data_generator(train_df, batch_size)\n",
    "\n",
    "# validation data generator \n",
    "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function that returns the base model\n",
    "def get_base_model():\n",
    "    base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "drop2 (Dropout)              (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 134,272,835\n",
      "Trainable params: 12,291\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the base model\n",
    "base_model = get_base_model()\n",
    "\n",
    "#  get the output of the second last dense layer \n",
    "base_model_output = base_model.layers[-2].output\n",
    "\n",
    "# add new layers \n",
    "x = Dropout(0.7,name='drop2')(base_model_output)\n",
    "output = Dense(3, activation='softmax', name='fc3')(x)\n",
    "\n",
    "# define a new model \n",
    "model = Model(base_model.input, output)\n",
    "\n",
    "# Freeze all the base model layers \n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# compile the model and check it \n",
    "optimizer = RMSprop(0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always user earlystopping\n",
    "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# checkpoint to save model\n",
    "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
    "\n",
    "# number of training and validation steps for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "\n",
    "# number of epochs \n",
    "nb_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-fbb3bffffdef>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_26.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_68.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_13.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_20.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_79.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_46.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_0.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_13.jpg\n",
      "Epoch 1/10\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_56.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_34.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_11.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_0.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_12.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_30.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_31.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_29.jpg\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 3.0154 - accuracy: 0.5000C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_5.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_64.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_42.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_52.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_80.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_17.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_53.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_60.jpg\n",
      " 2/30 [=>............................] - ETA: 15s - loss: 3.2253 - accuracy: 0.3125C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_59.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_33.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_81.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_25.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_19.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_77.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_21.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_16.jpg\n",
      " 3/30 [==>...........................] - ETA: 20s - loss: 2.8990 - accuracy: 0.2917C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_55.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_33.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_72.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_20.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_32.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_73.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_49.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_65.jpg\n",
      " 4/30 [===>..........................] - ETA: 22s - loss: 3.2562 - accuracy: 0.3125C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_38.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_45.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_55.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_56.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_50.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_66.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_28.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_62.jpg\n",
      " 5/30 [====>.........................] - ETA: 23s - loss: 2.9410 - accuracy: 0.3750C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_68.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_80.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_41.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_37.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_69.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_48.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_62.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_52.jpg\n",
      " 6/30 [=====>........................] - ETA: 23s - loss: 2.7767 - accuracy: 0.3750C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_75.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_37.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_57.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_6.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_46.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_67.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_57.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_18.jpg\n",
      " 7/30 [======>.......................] - ETA: 22s - loss: 3.2425 - accuracy: 0.3393C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_9.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_9.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_48.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_60.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_70.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_2.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_57.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_63.jpg\n",
      " 8/30 [=======>......................] - ETA: 22s - loss: 3.7155 - accuracy: 0.3281C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_28.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_71.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_58.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_45.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_81.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_30.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_47.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_5.jpg\n",
      " 9/30 [========>.....................] - ETA: 21s - loss: 3.6021 - accuracy: 0.3194C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_19.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_35.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_54.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_70.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_2.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_18.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_73.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_13.jpg\n",
      "10/30 [=========>....................] - ETA: 20s - loss: 3.4833 - accuracy: 0.3125C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_58.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_70.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_7.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_22.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_0.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_32.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_40.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_42.jpg\n",
      "11/30 [==========>...................] - ETA: 19s - loss: 3.3611 - accuracy: 0.3182C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_42.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_62.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_8.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_65.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_64.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_66.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_75.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_54.jpg\n",
      "12/30 [===========>..................] - ETA: 19s - loss: 3.3379 - accuracy: 0.3229C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_10.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_12.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_67.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_8.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_36.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_10.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_38.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_16.jpg\n",
      "13/30 [============>.................] - ETA: 18s - loss: 3.2092 - accuracy: 0.3365C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_56.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_15.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_21.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_68.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_77.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_17.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_30.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_8.jpg\n",
      "14/30 [=============>................] - ETA: 17s - loss: 3.0541 - accuracy: 0.3661C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_40.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_35.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_40.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_46.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_49.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_52.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_51.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_41.jpg\n",
      "15/30 [==============>...............] - ETA: 16s - loss: 3.1274 - accuracy: 0.3583C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_3.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_1.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_24.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_48.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_82.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_74.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_59.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_47.jpg\n",
      "16/30 [===============>..............] - ETA: 15s - loss: 3.0327 - accuracy: 0.3516C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_74.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_72.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_64.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_26.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_27.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_60.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_82.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_74.jpg\n",
      "17/30 [================>.............] - ETA: 14s - loss: 3.1270 - accuracy: 0.3382C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_75.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_10.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_80.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_78.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_61.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_79.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_29.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_43.jpg\n",
      "18/30 [=================>............] - ETA: 13s - loss: 3.1514 - accuracy: 0.3264C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_81.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_4.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_72.jpg\n",
      "19/30 [==================>...........] - ETA: 12s - loss: 3.0876 - accuracy: 0.3355C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_44.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_77.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_71.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_17.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_34.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_61.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_43.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_55.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_49.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_36.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_22.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_69.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_51.jpg\n",
      "20/30 [===================>..........] - ETA: 11s - loss: 3.2234 - accuracy: 0.3313C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_12.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_25.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_1.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_39.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_45.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_83.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_50.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_31.jpg\n",
      "21/30 [====================>.........] - ETA: 10s - loss: 3.2106 - accuracy: 0.3333C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_16.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_4.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_20.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_71.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_66.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_41.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_38.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_47.jpg\n",
      "22/30 [=====================>........] - ETA: 8s - loss: 3.1777 - accuracy: 0.3409 C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_35.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_65.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_24.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_53.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_1.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_78.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_6.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_14.jpg\n",
      "23/30 [======================>.......] - ETA: 7s - loss: 3.1219 - accuracy: 0.3587C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_50.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_43.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_51.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_21.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_69.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_14.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_76.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_79.jpg\n",
      "24/30 [=======================>......] - ETA: 6s - loss: 3.0275 - accuracy: 0.3646C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_53.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_23.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_67.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_37.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_18.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_78.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_44.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_24.jpg\n",
      "25/30 [========================>.....] - ETA: 5s - loss: 3.0225 - accuracy: 0.3650C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_11.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_7.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_63.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_26.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_36.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_39.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_25.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_27.jpg\n",
      "26/30 [=========================>....] - ETA: 4s - loss: 2.9730 - accuracy: 0.3654C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_73.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_29.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_44.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_3.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_32.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_5.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_15.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_27.jpg\n",
      "27/30 [==========================>...] - ETA: 3s - loss: 2.9361 - accuracy: 0.3750C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_11.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_33.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_61.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_2.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_15.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_14.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_3.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_63.jpg\n",
      "28/30 [===========================>..] - ETA: 2s - loss: 2.9194 - accuracy: 0.3839C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_9.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_76.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_34.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_28.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_22.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_58.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_54.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_23.jpg\n",
      "29/30 [============================>.] - ETA: 1s - loss: 2.8804 - accuracy: 0.3879C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_17.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\leopard\\leopard_0.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_16.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\t90\\t90_68.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_48.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_1.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_55.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\train\\abrams\\abrams_25.jpg\n",
      "30/30 [==============================] - ETA: 0s - loss: 2.8695 - accuracy: 0.3833C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_96.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_85.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_84.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_95.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_88.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_98.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_97.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_84.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_88.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_83.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_90.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_90.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_95.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_91.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_87.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_99.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_92.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_94.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_89.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_96.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_97.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_89.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_96.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_86.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_93.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_93.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_87.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_85.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_82.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_89.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_92.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_87.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_99.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_95.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_98.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_98.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_97.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_84.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_92.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_83.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_86.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_93.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_88.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_85.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_94.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_91.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_91.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_96.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\abrams\\abrams_85.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_84.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_95.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_88.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_98.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\t90\\t90_97.jpg\n",
      "C:\\Users\\tcttn\\Desktop\\tank\\data\\test\\leopard\\leopard_84.jpg\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xfe in position 179: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fbb3bffffdef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history1 = model.fit_generator(train_data_gen, \n\u001b[0m\u001b[0;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_train_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_data_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_valid_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1300\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m-> 1978\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   1979\u001b[0m                     signatures, options)\n\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    131\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[0;32m    134\u001b[0m                           signatures, options)\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    982\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[0;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n\u001b[1;32m--> 984\u001b[1;33m   object_saver.save(utils_impl.get_variables_path(export_dir),\n\u001b[0m\u001b[0;32m    985\u001b[0m                     options=ckpt_options)\n\u001b[0;32m    986\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0m\u001b[0;32m   1200\u001b[0m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0;32m   1201\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1144\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m           \u001b[1;31m# merged, attempts to delete the temporary directory,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m           \u001b[1;31m# \"<user-fed prefix>_temp\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m           return gen_io_ops.merge_v2_checkpoints(\n\u001b[0m\u001b[0;32m    282\u001b[0m               sharded_prefixes, file_prefix, delete_old_dirs=True)\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name)\u001b[0m\n\u001b[0;32m    502\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m       return merge_v2_checkpoints_eager_fallback(\n\u001b[0m\u001b[0;32m    505\u001b[0m           \u001b[0mcheckpoint_prefixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           delete_old_dirs=delete_old_dirs, name=name, ctx=_ctx)\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints_eager_fallback\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name, ctx)\u001b[0m\n\u001b[0;32m    527\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_prefixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_prefix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"delete_old_dirs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete_old_dirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m   _result = _execute.execute(b\"MergeV2Checkpoints\", 0, inputs=_inputs_flat,\n\u001b[0m\u001b[0;32m    530\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0;32m    531\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xfe in position 179: invalid start byte"
     ]
    }
   ],
   "source": [
    "history1 = model.fit_generator(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen, \n",
    "                              validation_steps=nb_valid_steps,\n",
    "                              callbacks=[es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history1.history['accuracy']\n",
    "valid_acc = history1.history['val_accuracy']\n",
    "\n",
    "# get the loss\n",
    "train_loss = history1.history['loss']\n",
    "valid_loss = history1.history['val_loss']\n",
    "\n",
    "# get the number of entries\n",
    "xvalues = np.arange(len(train_acc))\n",
    "\n",
    "# visualize\n",
    "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(xvalues, train_loss)\n",
    "ax[0].plot(xvalues, valid_loss)\n",
    "ax[0].set_title(\"Loss curve\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].legend(['train', 'validation'])\n",
    "\n",
    "ax[1].plot(xvalues, train_acc)\n",
    "ax[1].plot(xvalues, valid_acc)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].legend(['train', 'validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the final loss and accuracy on our validation data?\n",
    "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
    "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all the layers for which you want to visualize the outputs and store it in a list\n",
    "outputs = [layer.output for layer in model.layers[1:18]]\n",
    "\n",
    "# Define a new model that generates the above output\n",
    "vis_model = Model(model.input, outputs)\n",
    "\n",
    "# check if we have all the layers we require for visualization \n",
    "vis_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the layer names we are interested in\n",
    "layer_names = []\n",
    "for layer in outputs:\n",
    "    layer_names.append(layer.name.split(\"/\")[0])\n",
    "\n",
    "    \n",
    "print(\"Layers going to be used for visualization: \")\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CAM(processed_image, predicted_label):\n",
    "    \"\"\"\n",
    "    This function is used to generate a heatmap for a sample image prediction.\n",
    "    \n",
    "    Args:\n",
    "        processed_image: any sample image that has been pre-processed using the \n",
    "                       `preprocess_input()`method of a keras model\n",
    "        predicted_label: label that has been predicted by the network for this image\n",
    "    \n",
    "    Returns:\n",
    "        heatmap: heatmap generated over the last convolution layer output \n",
    "    \"\"\"\n",
    "    # we want the activations for the predicted label\n",
    "    #print(model.output)\n",
    "    predicted_output = model.output[:, predicted_label]\n",
    "    \n",
    "    # choose the last conv layer in your model\n",
    "    last_conv_layer = model.get_layer('block5_conv3')\n",
    "    \n",
    "    # get the gradients wrt to the last conv layer\n",
    "    #grads = K.gradients(predicted_output, last_conv_layer.output)[0]\n",
    "    \n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "      tape.watch(predicted_output)  # Since `a.build` has not been called at this point\n",
    "                                               # `a.variables` will return an empty list and the\n",
    "                                                # tape will not be watching anything.\n",
    "      result = last_conv_layer.output[0]\n",
    "      tape.gradient(result,predicted_output)  # The result of this computation will be\n",
    "                                                          # a list of `None`s since a's variables\n",
    "                                                          # are not being watched.\n",
    "    \n",
    "    # take mean gradient per feature map\n",
    "    grads = K.mean(result, axis=(0,1,2))\n",
    "    \n",
    "    # Define a function that generates the values for the output and gradients\n",
    "    evaluation_function = K.function([model.input], [grads, last_conv_layer.output[0]])\n",
    "    #print(evaluation_function([processed_image]))\n",
    "    # get the values\n",
    "    grads_values, conv_ouput_values = evaluation_function([processed_image])\n",
    "    print(grads_values)\n",
    "    # iterate over each feature map in yout conv output and multiply\n",
    "    # the gradient values with the conv output values. This gives an \n",
    "    # indication of \"how important a feature is\"\n",
    "    for i in range(512): # we have 512 features in our last conv layer\n",
    "        conv_ouput_values[:,:,i] *= grads_values\n",
    "    \n",
    "    # create a heatmap\n",
    "    heatmap = np.mean(conv_ouput_values, axis=-1)\n",
    "    \n",
    "    # remove negative values\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    \n",
    "    # normalize\n",
    "    heatmap /= heatmap.max()\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_sample(idx):\n",
    "    \"\"\"\n",
    "    This function is used to select a random sample from the validation dataframe.\n",
    "    It generates prediction for the same. It also stores the heatmap and the intermediate\n",
    "    layers activation maps.\n",
    "    \n",
    "    Arguments:\n",
    "        idx: random index to select a sample from validation data\n",
    "    \n",
    "    Returns:\n",
    "        activations: activation values for intermediate layers\n",
    "    \"\"\"\n",
    "    # select the sample and read the corresponding image and label\n",
    "    sample_image = cv2.imread(valid_df.iloc[idx]['image'])\n",
    "    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "    sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n",
    "    sample_label = valid_df.iloc[idx][\"label\"]\n",
    "    \n",
    "    # pre-process the image\n",
    "    sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
    "    #print(np.expand_dims(sample_image, axis=0))\n",
    "    sample_image_processed = preprocess_input(sample_image_processed)\n",
    "    #print(preprocess_input(sample_image_processed))\n",
    "    \n",
    "    # generate activation maps from the intermediate layers using the visualization model\n",
    "    activations = vis_model.predict(sample_image_processed)\n",
    "    #print(vis_model.predict(sample_image_processed))\n",
    "    \n",
    "    # get the label predicted by our original model\n",
    "    pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
    "    #print(pred_label)\n",
    "    \n",
    "    # choose any random activation map from the activation maps \n",
    "    sample_activation = activations[0][0,:,:,32]\n",
    "    #print(sample_activation)\n",
    "    \n",
    "    # normalize the sample activation map\n",
    "    sample_activation-=sample_activation.mean()\n",
    "    sample_activation/=sample_activation.std()\n",
    "    \n",
    "    # convert pixel values between 0-255\n",
    "    sample_activation *=255\n",
    "    sample_activation = np.clip(sample_activation, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the heatmap for class activation map(CAM)\n",
    "    #print(sample_image_processed)\n",
    "    #print(pred_label)\n",
    "    heatmap = get_CAM(sample_image_processed, pred_label)\n",
    "    #print(heatmap)\n",
    "    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n",
    "    heatmap = heatmap *255\n",
    "    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    super_imposed_image = heatmap * 0.5 + sample_image\n",
    "    super_imposed_image = np.clip(super_imposed_image, 0,255).astype(np.uint8)\n",
    "\n",
    "    f,ax = plt.subplots(2,2, figsize=(15,8))\n",
    "    ax[0,0].imshow(sample_image)\n",
    "    ax[0,0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label}\")\n",
    "    ax[0,0].axis('off')\n",
    "    \n",
    "    ax[0,1].imshow(sample_activation)\n",
    "    ax[0,1].set_title(\"Random feature map\")\n",
    "    ax[0,1].axis('off')\n",
    "    \n",
    "    ax[1,0].imshow(heatmap)\n",
    "    ax[1,0].set_title(\"Class Activation Map\")\n",
    "    ax[1,0].axis('off')\n",
    "    \n",
    "    ax[1,1].imshow(super_imposed_image)\n",
    "    ax[1,1].set_title(\"Activation map superimposed\")\n",
    "    ax[1,1].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations= show_random_sample(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_intermediate_activations(layer_names, activations):\n",
    "    \"\"\"\n",
    "    This function is used to visualize all the itermediate activation maps\n",
    "    \n",
    "    Arguments:\n",
    "        layer_names: list of names of all the intermediate layers we chose\n",
    "        activations: all the intermediate activation maps \n",
    "    \"\"\"\n",
    "    assert len(layer_names)==len(activations), \"Make sure layers and activation values match\"\n",
    "    images_per_row=16\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        nb_features = layer_activation.shape[-1]\n",
    "        size= layer_activation.shape[1]\n",
    "\n",
    "        nb_cols = nb_features // images_per_row\n",
    "        grid = np.zeros((size*nb_cols, size*images_per_row))\n",
    "\n",
    "        for col in range(nb_cols):\n",
    "            for row in range(images_per_row):\n",
    "                feature_map = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                feature_map -= feature_map.mean()\n",
    "                feature_map /= feature_map.std()\n",
    "                feature_map *=255\n",
    "                feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "\n",
    "                grid[col*size:(col+1)*size, row*size:(row+1)*size] = feature_map\n",
    "\n",
    "        scale = 1./size\n",
    "        plt.figure(figsize=(scale*grid.shape[1], scale*grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all the activation maps for this sample\n",
    "visualize_intermediate_activations(activations=activations, layer_names=layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx=200\n",
    "activations= show_random_sample(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx=183\n",
    "activations= show_random_sample(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx=1\n",
    "activations= show_random_sample(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx=2\n",
    "activations= show_random_sample(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, idx in enumerate(next_batch_indices):\n",
    "                #print(data.iloc[idx][\"image\"])\n",
    "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
    "                #print(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                #print(data.iloc[idx][\"label\"])\n",
    "                label = data.iloc[idx][\"label\"]\n",
    "                \n",
    "                if not is_validation_data:\n",
    "                    img = seq.augment_image(img)\n",
    "                #print(img.size)\n",
    "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_generator(valid_df, batch_size=1, is_validation_data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(data_generator(valid_df, batch_size=1, is_validation_data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels from one-hot encoded\n",
    "predictions = [i.argmax() for i in preds]\n",
    "y_true = [i.argmax() for i in sample_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names,title='Confusion matrix',cmap=None,normalize=False):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float32') / cm.sum(axis=1)\n",
    "        cm = np.round(cm,2)\n",
    "        \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel(\"Predicted label\\naccuracy={:0.4f}\\n misclass={:0.4f}\".format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
    "plot_confusion_matrix(cm, normalize=True, target_names=labels_dict.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
