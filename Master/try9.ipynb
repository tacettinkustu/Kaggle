{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in c:\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: Shapely in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda3\\lib\\site-packages (from imgaug) (3.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\anaconda3\\lib\\site-packages (from imgaug) (7.2.0)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.5.0)\n",
      "Requirement already satisfied: imageio in c:\\anaconda3\\lib\\site-packages (from imgaug) (2.9.0)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\anaconda3\\lib\\site-packages (from imgaug) (0.16.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\anaconda3\\lib\\site-packages (from imgaug) (1.18.5)\n",
      "Requirement already satisfied: opencv-python in c:\\anaconda3\\lib\\site-packages (from imgaug) (4.2.0.34)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->imgaug) (2.4.7)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.2)\n",
      "Requirement already satisfied: mlxtend in c:\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from mlxtend) (49.2.0.post20200714)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imgaug\n",
    "!pip install mlxtend\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Path('C:/Users/tcttn/Desktop/photos/train/') \n",
    "validation_data = Path('C:/Users/tcttn/Desktop/photos/test/')\n",
    "labels_path = Path('C:/Users/tcttn/Desktop/photos/weapons.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'aircrafts', 1: 'grenades', 2: 'handguns', 3: 'machineguns', 4: 'RPG', 5: 'tanks'}\n"
     ]
    }
   ],
   "source": [
    "labels_dict= {'aircrafts':0, 'grenades':1, 'handguns':2, 'machineguns':3, 'RPG':4, 'tanks':5}\n",
    "\n",
    "# map labels to common names\n",
    "names_dict = dict(zip(labels_dict.values(), labels_dict.keys()))\n",
    "print(names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traininng samples:  7124\n",
      "Number of validation samples:  1887\n",
      "\n",
      "                                                image  label\n",
      "0  C:\\Users\\tcttn\\Desktop\\photos\\train\\machinegun...      3\n",
      "1     C:\\Users\\tcttn\\Desktop\\photos\\train\\RPG\\69.jpg      4\n",
      "2  C:\\Users\\tcttn\\Desktop\\photos\\train\\aircrafts\\...      0\n",
      "3  C:\\Users\\tcttn\\Desktop\\photos\\train\\handguns\\2...      2\n",
      "4  C:\\Users\\tcttn\\Desktop\\photos\\train\\aircrafts\\...      0 \n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "                                                image  label\n",
      "0  C:\\Users\\tcttn\\Desktop\\photos\\test\\grenades\\12...      1\n",
      "1  C:\\Users\\tcttn\\Desktop\\photos\\test\\tanks\\war_t...      5\n",
      "2  C:\\Users\\tcttn\\Desktop\\photos\\test\\aircrafts\\e...      0\n",
      "3  C:\\Users\\tcttn\\Desktop\\photos\\test\\grenades\\10...      1\n",
      "4  C:\\Users\\tcttn\\Desktop\\photos\\test\\grenades\\10...      1\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "for folder in os.listdir(training_data):\n",
    "    # Define the path to the images\n",
    "    imgs_path = training_data / folder\n",
    "    \n",
    "    # Get the list of all the images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    \n",
    "    # Store each image path and corresponding label \n",
    "    for img_name in imgs:\n",
    "        train_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Creating dataframe for validation data in a similar fashion\n",
    "valid_df = []\n",
    "for folder in os.listdir(validation_data):\n",
    "    imgs_path = validation_data / folder\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    for img_name in imgs:\n",
    "        valid_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "        \n",
    "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# How many samples do we have in our training and validation data?\n",
    "print(\"Number of traininng samples: \", len(train_df))\n",
    "print(\"Number of validation samples: \", len(valid_df))\n",
    "\n",
    "# sneak peek of the training and validation dataframes\n",
    "print(\"\\n\",train_df.head(), \"\\n\")\n",
    "print(\"=================================================================\\n\")\n",
    "print(\"\\n\", valid_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants(not truly though!) \n",
    "\n",
    "# dimensions to consider for the images\n",
    "img_rows, img_cols, img_channels = 224,224,3\n",
    "\n",
    "# batch size for training  \n",
    "batch_size=120\n",
    "\n",
    "# total number of classes in the dataset\n",
    "nb_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence \n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, batch_size, is_validation_data=False):\n",
    "    #print(\"hello\")\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    nb_batches = int(np.ceil(n/batch_size))\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        if not is_validation_data:\n",
    "            # shuffle indices for the training data\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        for i in range(nb_batches):\n",
    "            # get the next batch \n",
    "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            # process the next batch\n",
    "            for j, idx in enumerate(next_batch_indices):\n",
    "                #print(data.iloc[idx][\"image\"])\n",
    "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
    "                #print(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                #print(data.iloc[idx][\"label\"])\n",
    "                label = data.iloc[idx][\"label\"]\n",
    "                \n",
    "                if not is_validation_data:\n",
    "                    img = seq.augment_image(img)\n",
    "                #print(img.size)\n",
    "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
    "            #print(preprocess_input(batch_data))\n",
    "            batch_data = preprocess_input(batch_data)\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = data_generator(train_df, batch_size)\n",
    "\n",
    "# validation data generator \n",
    "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function that returns the base model\n",
    "def get_base_model():\n",
    "    base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "drop2 (Dropout)              (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 134,285,126\n",
      "Trainable params: 24,582\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the base model\n",
    "base_model = get_base_model()\n",
    "\n",
    "#  get the output of the second last dense layer \n",
    "base_model_output = base_model.layers[-2].output\n",
    "\n",
    "# add new layers \n",
    "x = Dropout(0.7,name='drop2')(base_model_output)\n",
    "output = Dense(6, activation='softmax', name='fc3')(x)\n",
    "\n",
    "# define a new model \n",
    "model = Model(base_model.input, output)\n",
    "\n",
    "# Freeze all the base model layers \n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# compile the model and check it \n",
    "optimizer = RMSprop(0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always user earlystopping\n",
    "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# checkpoint to save model\n",
    "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
    "\n",
    "# number of training and validation steps for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "\n",
    "# number of epochs \n",
    "nb_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-fbb3bffffdef>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit_generator(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen, \n",
    "                              validation_steps=nb_valid_steps,\n",
    "                              callbacks=[es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
